spring:
  cloud:
    function:
      definition: supplier
    stream:
      bindings:
        supplier-out-0:
          destination: sensor-topic
          content-type: application/*+avro
#          Commenting out this allows schema evolution to work properly but the schema and messages
#          produced in Kafka are just bytes, so you can't view the schema with Confluent Control Center
          producer:
            useNativeEncoding: true

      kafka:
        binder:
          autoAddPartitions: true
          minPartitionCount: 8
        bindings:
          supplier-out-0:
            producer:
              configuration:
                key.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
                value.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
                schema.registry.url: http://localhost:8081
                auto.register.schemas: true